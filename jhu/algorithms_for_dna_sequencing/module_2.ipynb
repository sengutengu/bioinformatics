{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31e35b44-3357-49c7-8648-fa42b879cb05",
   "metadata": {},
   "source": [
    "## Module 2. Preprocessing, Indexing, and Approximate Matching\n",
    "\n",
    "This week, we'll look at the **Boyer-Moore** algorithm. It is similar to naive exact matching in some ways in that it will still try character alignments, but it'll skip any alignments it can.\n",
    "\n",
    "The insight is as follows. Given $T$ = `there would have been a time for such a word` and $P$ = `word`, if we see that `word` does not align with `woul`:\n",
    "\n",
    "```\n",
    "there would have been a time for such a word\n",
    "      word\n",
    "      >>*\n",
    "```\n",
    "\n",
    "Because `u` does not occur anywhere within `word`, we can skip two alignments to the position to the right of `u`.\n",
    "\n",
    "```\n",
    "there would have been a time for such a word\n",
    "       >>word\n",
    "```\n",
    "\n",
    "Boyer-Moore makes a further modification to the naive algorithm. It still tries alignments left-to-right, but it tries character comparisons **right-to-left**. \n",
    "\n",
    "### Bad Character Rule\n",
    "\n",
    "Furthermore, in what we call the **bad character rule**, upon finding a mismatch, we skip alignments until:\n",
    "* the mismatch becomes a match, or\n",
    "* the pattern moves past the mismatch.\n",
    "\n",
    "Given the following, with a mismatch at the fourth position from the right:\n",
    "\n",
    "```\n",
    "GCTTCTGCTACCTTTTGCGC\n",
    "CCTTTTGC\n",
    "    *<<<\n",
    "```\n",
    "\n",
    "We skip two alignments until we hit a `C` in the pattern. Then, we try the character comparison again:\n",
    "```\n",
    "GCTTCTGCTACCTTTTGCGC\n",
    " >>CCTTTTGC\n",
    "         *<\n",
    "```\n",
    "\n",
    "We have another match, this time the second from the right. And since there is no `A` in the pattern, we move to the right of `A` entirely, skipping six alignments. Then, we try the character comparisons again, and find that we have a match.\n",
    "\n",
    "```\n",
    "GCTTCTGCTACCTTTTGCGC\n",
    "    >>>>>>CCTTTTGC\n",
    "          <<<<<<<<\n",
    "```\n",
    "\n",
    "### Good Suffix Rule\n",
    "\n",
    "Boyer-Moore also has another rule: the **good suffix rule**. If we find a substring *t* in the text that matches a suffix of the pattern, then we skip alignments until we find:\n",
    "* Another *t* within the pattern,\n",
    "* A prefix of the pattern that matches a suffix of *t*, or\n",
    "* until the pattern moves past *t* entirely.\n",
    "\n",
    "Given the following, we have a *t* = `TAC`, followed by a mismatch.\n",
    "\n",
    "```\n",
    "      ...\n",
    "CGTGCCTACTTACTTACTTACTTA\n",
    "CTTACTTAC\n",
    "     *<<<\n",
    "```\n",
    "\n",
    "Then, we skip three alignments, until we find another `TAC` in the pattern. We perform our character comparisons again, and find that we have a new *t* = `TACTTAC`. \n",
    "\n",
    "```\n",
    "      .......\n",
    "CGTGCCTACTTACTTACTTACTTA\n",
    " >>>CTTACTTAC\n",
    "     *<<<<<<<       \n",
    "```\n",
    "\n",
    "Because *t* does not exist anywhere downstream in the pattern, we skip forward three alignments (by applying the bad character rule), and find a match. \n",
    "\n",
    "```\n",
    "CGTGCCTACTTACTTACTTACTTA\n",
    "     >>>CTTACTTAC\n",
    "        <<<<<<<<<       \n",
    "```\n",
    "\n",
    "### Putting It All Together\n",
    "\n",
    "Let's put it all together. If we can apply both rules, we take whichever returns the larger skip. Given the following example, the very first character comparison results in a mismatch. \n",
    "\n",
    "```\n",
    "GTTATAGCTGATCGCGGCGTAGCGGCGAA\n",
    "GTAGCGGCG\n",
    "        *\n",
    "```\n",
    "\n",
    "There is no good suffix (gs: 0), but the bad character rule gives us six alignment skips (bc: 6), so apply the bad character rule. Then, we perform character comparisons again to find that we have a bad character at the fourth comparison, but also a good suffix *t* = `GCG`. \n",
    "\n",
    "```\n",
    "             ...\n",
    "GTTATAGCTGATCGCGGCGTAGCGGCGAA\n",
    " >>>>>>GTAGCGGCG\n",
    "            *<<<\n",
    "```\n",
    "\n",
    "Applying the bad character rule gives us 0 alignment skips (bs: 0), while applying the good suffix rule gives us 2 alignment skips (gc: 2), so we go with the good suffix rule. \n",
    "\n",
    "```\n",
    "             ......\n",
    "GTTATAGCTGATCGCGGCGTAGCGGCGAA\n",
    "        >>GTAGCGGCG\n",
    "            *<<<<<<\n",
    "```\n",
    "\n",
    "Now, the bad character rule gives us 2 alignment skips to the right of `C` (bc: 2), but the good suffix rule gives us 7 alignment skips (gs: 7; the prefix `G` of the pattern matches the suffix `G` of *t*), so we go with the good suffix rule. \n",
    "\n",
    "```\n",
    "GTTATAGCTGATCGCGGCGTAGCGGCGAA\n",
    "           >>>>>>>GTAGCGGCG\n",
    "                  <<<<<<<<<\n",
    "```\n",
    "\n",
    "And now we have a match. In total, we skipped 15 alignments in this example, and we totally ignored 11 characters. This makes Boyer-Moore substantially faster than the naive exact match algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6596b2-ef02-465e-9eaa-8627c24311fa",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Another advantage of Boyer-Moore is the **preprocessing**. Boyer-Moore creates, for the pattern *P*, a lookup table for the bad character rule and another lookup table for the good suffix rule for **all possible mismatch scenarios** before the algorithm is run. For the **bad character rule**, we build a lookup table of the requisite number of skips for each character of pattern *P*, for every character in the alphabet. For example, given *P* = `TCGC`, we build the lookup table as follows:\n",
    "\n",
    "```\n",
    "  T C G C\n",
    "A 0 1 2 3  # A is not in P, so we have to skip all the way past A.\n",
    "C 0 - 0 -  # Encountering C at G means we just look at the next char (C)\n",
    "G 0 1 - 0\n",
    "T - 0 1 2  # Have to skip to where T is in P\n",
    "```\n",
    "\n",
    "One might wonder whether we can preprocess the text *T* rather than the pattern *P*. It is actually possible, and it can be a good idea if we are searching through *T* multiple times. An algorithm that preprocesses the text is called an **offline algorithm**; an algorithm that does not is an **online algorithm**. An offline algorithm may or may not preprocess the pattern *P*. \n",
    "\n",
    "So, a naive exact matching algorithm is an online algorithm, and so is Boyer-Moore. But a modern search engine likely uses an offline algorithm to be able to search through a very large *T* and return a result quickly. Likewise, a search through a reference genome might want to use an offline algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c86a314-8d9a-4174-af87-18e2ae942c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5da90370-8b4a-4adc-b983-c3e12b8d4e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c87f2684-ebda-46a9-802f-d945c38e32a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = \"AATTTG\"\n",
    "t = \"CACTTAATTTG\"\n",
    "p_bm = BoyerMoore(p, alphabet='ACGT')\n",
    "boyer_moore(p, p_bm, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f8f06-97f0-4933-b88b-ab359ae3509c",
   "metadata": {},
   "source": [
    "### *k*-mer Ordered Index\n",
    "\n",
    "How might we preprocess the text *T*? One good way is to implement an **ordered index**. Given a short text *T* = `GTGCGTGTGGGGG` and *k*=3, we can create an index of 3-mers as follows:\n",
    "\n",
    "`{GTG: 0, TGC: 1, GCG: 2, CGT: 3, GTG: 4, TGT: 5, GTG: 6, TGG: 7, GGG: 8, GGG: 9, GGG: 10}`\n",
    "\n",
    "Then, we sort the keys alphabetically. \n",
    "\n",
    "`{CGT: 3, GCG: 2, GGG: 8, GGG: 9, GGG: 10, GTG: 0, GTG: 4, GTG: 6, TGC: 1, TGG: 7, TGT: 5}`\n",
    "\n",
    "Sorting the keys allows us to use a **binary search** to efficiently locate the key, and thereby the location of the 3-mer in *T*. Python provides a `bisect.bisect_left(a, x)` function which looks in a sorted list `a` the leftmost position at which variable `x` can be inserted to maintain order, which will be useful in implementing a binary search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c53126e-fbc8-4ec1-b0a6-5f717443791e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bisect\n",
    "a = [\"CGT\", \"GCG\", \"GGG\", \"GGG\", \"GGG\", \"GTG\", \"GTG\", \"GTG\", \"TGC\", \"TGG\", \"TGT\"]\n",
    "bisect.bisect_left(a, \"GTG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b8ece5-53d2-4c88-b00b-75f851b6490f",
   "metadata": {},
   "source": [
    "In the above example, once we've found the leftmost position where `GTG` can be inserted and still maintain order, we just try all the `GTG`s and see at what positions we find hits (0, 4, and 6). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf90c1-6626-4de1-813e-cf09ccf4536c",
   "metadata": {},
   "source": [
    "### Detour: Hash Tables\n",
    "\n",
    "We can also use another data structure, a **hash table**, to represent the same kind data structure as the *k*-mer ordered index. In a hash table, we have a list of \"buckets\", and a hash function assigns each *k*-mer to a bucket. Each *k*-mer entry is a 3-long list, consisting of the *k*-mer, the position in *T*, and a null pointer which can be modified to point to another *k*-mer entry if the hash function assigns another *k*-mer to the same bucket. \n",
    "\n",
    "When different *k*-mers are assigned to the same bucket, we call it a **collision**. It's not unexpected since there are many more *k*-mers than there are buckets, but many collisions can slow down the querying. \n",
    "\n",
    "When we want to query from the hash table, we use the hash function to tell us in which bucket we can find the query string. Then, we look at the entries in that bucket and look for the right keys.\n",
    "\n",
    "In Python, a dictionary *is* a hash table, so it's quite easy. All the nitty-gritty of the hash function is hidden from us, but that's not such a bad thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b3212b-53cd-4645-a860-cb5faef67745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 10]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 'GTGCGTGTGGGGG'\n",
    "table = {'CGT': [3], 'GCG': [2], 'GGG': [8, 9, 10], 'GTG': [0, 4, 6], 'TGC': [1], 'TGG': [7], 'TGT': [5]}\n",
    "table['GGG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61faea5d-3f17-4b4e-9440-2630ed4b67e9",
   "metadata": {},
   "source": [
    "### Implementing a *k*-mer index\n",
    "To implement a *k*-mer index, we do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86e783f0-68d3-40e0-8f23-f57dca385553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect # use binary search from bisect library\n",
    "\n",
    "class Index: # create an Index object\n",
    "\n",
    "    # init method preprocesses string\n",
    "    def __init__(self, t, k):\n",
    "        self.k = k\n",
    "        self.index = [(t[i:i+k], i) for i in range(len(t)-k+1)] # list of tuples\n",
    "        self.index.sort() # sort for binary search\n",
    "\n",
    "    # query method \n",
    "    def query(self, p): \n",
    "        kmer = p[:self.k] # get the first k-mer from pattern\n",
    "        \n",
    "        # return index of the first occurrence of (kmer, n) in self.index\n",
    "        # search for position for (kmer, -1) to ensure leftmost found\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1)) \n",
    "        \n",
    "        hits = []\n",
    "        \n",
    "        while i < len(self.index): # iterate through the right \"half\" of self.index\n",
    "            \n",
    "            if self.index[i][0] != kmer:\n",
    "                # if kmer no longer matches then no point in continuing comparison\n",
    "                break \n",
    "            \n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9ac157-6d6d-4bbc-b4ed-6b05e2e0960b",
   "metadata": {},
   "source": [
    "Because I'm not used to using classes in Python, just a note for myself: if we don't use `__init__()`, we have to set up the values for each instance of a class object like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d39d8bb-39f1-4c1a-885f-facbc4882fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 GTGCGTGTGGGGG\n"
     ]
    }
   ],
   "source": [
    "class IndexNoInit:\n",
    "        # query method \n",
    "    def hello_world():\n",
    "        print(\"hello world\")\n",
    "        \n",
    "ind = IndexNoInit()\n",
    "ind.k = 3\n",
    "ind.t = 'GTGCGTGTGGGGG'\n",
    "print(ind.k, ind.t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7f1b3-bfb9-4d0b-a73e-cdfc9d94aa45",
   "metadata": {},
   "source": [
    "And the `self` syntax makes it so that when we create a new instance of a class object, the assignment in `__init__()` is stored within that instance. Without the `self` syntax, the variable assignment in `__init__()` disappears after `__init__()` finishes running, and we cannot refer to the variables later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d44f49ea-59ce-420d-bb2c-63d876dcbd19",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'IndexNoSelf' object has no attribute 'k'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhello world\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m ind \u001b[38;5;241m=\u001b[39m IndexNoSelf(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGTGCGTGTGGGGG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mind\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'IndexNoSelf' object has no attribute 'k'"
     ]
    }
   ],
   "source": [
    "class IndexNoSelf:\n",
    "    def __init__(self, k, t):\n",
    "        k = k\n",
    "        index = [(t[i:i+k], i) for i in range(len(t)-k+1)] # list of tuples\n",
    "        index.sort() # sort for binary search\n",
    "        \n",
    "    def hello_world():\n",
    "        print(\"hello world\")\n",
    "\n",
    "ind = IndexNoSelf(3, 'GTGCGTGTGGGGG')\n",
    "ind.k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866ee0e-ef46-4339-bf01-72160b733a2f",
   "metadata": {},
   "source": [
    "OK, back to implementing our *k*-mer indexing. Now, we can write a wrapper function to feed everything into our Index class and return a list of hit positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccd82405-9743-447a-b38c-3067de85be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_index(pattern, text, index):\n",
    "    k = index.k\n",
    "    hits = index.query(pattern)\n",
    "    offsets = [i for i in hits if pattern[k:] == text[i+k:i+len(pattern)]]\n",
    "    return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb36712d-17a2-4825-aa25-b0f6936f1e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 14]\n"
     ]
    }
   ],
   "source": [
    "text = \"GCTACGATCTAGAATCTATCTG\"\n",
    "pattern = \"TCTA\"\n",
    "print(query_index(pattern, text, Index(text, 2))) # k < len(pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43332b96-c028-4800-91e2-b024ea7b9e3d",
   "metadata": {},
   "source": [
    "### Variations on *k*-mer indexing\n",
    "\n",
    "We can save time on our binary searching, and save a little memory, by creating an index using every other *k*-mer in *T* (i.e. only even or only odd). When we do this, we just have to search for a *k*-mer at two adjacent offsets.\n",
    "\n",
    "You can also do subsequence matching, which can have a pretty large performance gain.\n",
    "\n",
    "You can also create a suffix index. All you have to do is store a list of indices so the index grows in linear space. \n",
    "\n",
    "The Burrows-Wheeler transform can be used to create an \"FM index\" that is very compact.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d46940-8a59-49f8-ab16-9c8b1252e775",
   "metadata": {},
   "source": [
    "### Approximate Matching\n",
    "\n",
    "In reality, exact matching is not what we want because sequencing reads have errors. We have to be able to account for some amount of error, as well as differences between individuals, by looking for approximate matches. \n",
    "\n",
    "The different kinds of differences are:\n",
    "* Substitution\n",
    "* Insertion\n",
    "* Deletion\n",
    "\n",
    "**Hamming distance** deals only with substitutions. \n",
    "\n",
    "**Edit distance** (**Levenshtein distance**) deals with substitutions, insertions, and deletions.\n",
    "\n",
    "Can we modify our earlier naive exact matching algorithm to account for approximate matches? Yes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "220e4d01-d125-4997-a127-b054687e5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0990c23-5246-49ad-bbc6-d0b059a0e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_hamming(p, t, max_mismatch):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        num_mismatch = 0 # add mismatch counter\n",
    "        for j in range(len(p)):\n",
    "            if t[i+j] != p[j]:\n",
    "                num_mismatch += 1\n",
    "                if num_mismatch > max_mismatch:\n",
    "                    break\n",
    "        if num_mismatch < max_mismatch:\n",
    "            occurrences.append(i)\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9511f8a2-a347-41d5-ae93-862ea0891b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 7, 14, 18]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"GCTACGATCTAGAATCTATCTG\"\n",
    "pattern = \"TCTA\"\n",
    "naive_hamming(pattern, text, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5229f5-6697-48e7-bfa3-ebf76044041f",
   "metadata": {},
   "source": [
    "### Pigeonhole Principle\n",
    "\n",
    "But adopting something like Boyer-Moore to look for approximate matching is harder. Using the **pigeonhole principle** will allow us to look for approximate matches more generally.\n",
    "\n",
    "The idea is that, if we allow *n* mismatches, then if we divide the pattern *P* into *n*+1 subsections, at least one of the subsections must be free of mismatches.\n",
    "\n",
    "So, if we find a subsection as an index hit, we check all the other subsections and make sure we are below *k* mismatches in a **verification step**.\n",
    "\n",
    "Let's implement the pigeonhole principle with Boyer-Moore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94c67633-1bdb-49fc-ac20-9e86d43ab825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_match(p, t, n):\n",
    "    \n",
    "    segment_length = round(len(p)/(n+1))\n",
    "    all_matches = set()\n",
    "\n",
    "    # for each of the n+1 segments of the pattern\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "\n",
    "        # run BM on the segment\n",
    "        p_bm = BoyerMoore(p[start:end], alphabet=\"ACGT\")\n",
    "\n",
    "        # get matches in text\n",
    "        matches = boyer_moore(p[start:end], p_bm, t)\n",
    "\n",
    "        for m in matches:\n",
    "\n",
    "            # if match occurs outside the length of the pattern\n",
    "            # (i.e. all the n+1 segments combined)\n",
    "            # then we ignore\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "                \n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m-start)\n",
    "                \n",
    "    return list(all_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8de4d061-7074-48f4-ba89-15c98c0f42c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 'AACTTG'\n",
    "t = 'CACTTAATTTG'\n",
    "approximate_match(p, t, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f99a71e-f4b8-471c-b0a4-afcca6641137",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "### Q1 & 2 \n",
    "\n",
    "How many alignments does the naive exact matching algorithm try when matching the string GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)\n",
    "\n",
    "How many character comparisons does the naive exact matching algorithm try when matching the string GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce023869-67a2-490c-9b65-33b36ce1facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_genome(filename):\n",
    "    f = open(filename, \"r\")\n",
    "    genome = f.read().split(\"\\n\")[1:]\n",
    "    f.close()\n",
    "    return \"\".join(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6685efdf-d63f-4900-9b8c-0fd3aa379046",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromosome = read_genome('genomes/chr1.GRCh38.excerpt.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a8bdaf-446a-4b53-a8ee-195991abc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_with_counts(p, t):\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_char_comparisons = 0\n",
    "    for i in range(len(t) - len(p) + 1):\n",
    "        match = True\n",
    "        for j in range(len(p)):\n",
    "            num_char_comparisons += 1\n",
    "            if t[i+j] != p[j]:\n",
    "                match = False\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)\n",
    "        num_alignments += 1\n",
    "    print(f'Number of character comparisons: {num_char_comparisons}')\n",
    "    print(f'Number of alignments: {num_alignments}')\n",
    "    return occurrences, num_alignments, num_char_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee9baea9-6745-4de9-92f9-e1c40648a27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of character comparisons: 984143\n",
      "Number of alignments: 799954\n"
     ]
    }
   ],
   "source": [
    "pattern = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "a, b, c = naive_with_counts(pattern, chromosome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5f5f9a-e8f4-415a-881f-5f0154d30665",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "How many alignments does Boyer-Moore try when matching the string GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG (derived from human Alu sequences) to the excerpt of human chromosome 1?  (Don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8a95a37-e673-41c7-b1d9-40933d5a1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    \"\"\" Do Boyer-Moore matching \"\"\"\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if p[j] != t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "        num_alignments += 1\n",
    "    print(f'Number of alignments: {num_alignments}')\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b15d2974-6dcc-4da0-bf9b-9c1e8d20b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of alignments: 127974\n"
     ]
    }
   ],
   "source": [
    "p_bm = BoyerMoore(pattern, alphabet='ACGT')\n",
    "a = boyer_moore_with_counts(pattern, p_bm, chromosome)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026b5ba-3107-4b2b-8b9c-d97961edf813",
   "metadata": {},
   "source": [
    "### Q4. Index-assisted approximate matching\n",
    "\n",
    "In practicals, we built a Python class called `Index` implementing an ordered-list version of the k-mer index. The `Index` class is copied below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b01a234b-bbb0-4add-ba05-aedf2534910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect # use binary search from bisect library\n",
    "\n",
    "class Index: # create an Index object\n",
    "\n",
    "    # init method preprocesses string\n",
    "    def __init__(self, t, k):\n",
    "        self.k = k\n",
    "        self.index = [(t[i:i+k], i) for i in range(len(t)-k+1)] # list of tuples\n",
    "        self.index.sort() # sort for binary search\n",
    "\n",
    "    # query method \n",
    "    def query(self, p): \n",
    "        kmer = p[:self.k] # get the first k-mer from pattern\n",
    "        \n",
    "        # return index of the first occurrence of (kmer, n) in self.index\n",
    "        # search for position for (kmer, -1) to ensure leftmost found\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1)) \n",
    "        \n",
    "        hits = []\n",
    "        \n",
    "        while i < len(self.index): # iterate through the right \"half\" of self.index\n",
    "            \n",
    "            if self.index[i][0] != kmer:\n",
    "                # if kmer no longer matches then no point in continuing comparison\n",
    "                break \n",
    "            \n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6db6b7-8b20-4c5c-adb0-4074130becb2",
   "metadata": {},
   "source": [
    "We also implemented the pigeonhole principle using Boyer-Moore as our exact matching algorithm.\n",
    "\n",
    "Implement the pigeonhole principle using `Index` to find exact matches for the partitions. Assume *P* always has length 24, and that we are looking for approximate matches with up to 2 mismatches (substitutions). We will use an 8-mer index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "941be51e-53c6-4522-8297-cf901bdab5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_approximate_match(p, t, n):\n",
    "    \n",
    "    segment_length = round(len(p)/(n+1))\n",
    "    all_matches = set()\n",
    "    ind = Index(t, 8)\n",
    "    ind_hits = 0\n",
    "\n",
    "    # for each of the n+1 segments of the pattern\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        matches = ind.query(p[start:end])\n",
    "        for m in matches:\n",
    "            ind_hits += 1\n",
    "\n",
    "            # if match occurs outside the length of the pattern\n",
    "            # (i.e. all the n+1 segments combined)\n",
    "            # then we ignore\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "                \n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m-start)\n",
    "                \n",
    "    return list(all_matches), ind_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e0a013ef-5b80-45aa-9d31-61a28a30b8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "a, b = index_approximate_match('GGCGCGGTGGCTCACGCCTGTAAT', chromosome, 2)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8fef3-a722-4de6-8291-f9bab8954993",
   "metadata": {},
   "source": [
    "### Q5. \n",
    "\n",
    "Using the instructions given in Question 4, how many total index hits are there when searching for occurrences of GGCGCGGTGGCTCACGCCTGTAAT with up to 2 substitutions in the excerpt of human chromosome 1? (Don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a045d6cc-0c93-491b-be37-218187312e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195e8c4d-c465-4668-bc98-8f388c53b057",
   "metadata": {},
   "source": [
    "### Q6.\n",
    "\n",
    "Let's examine whether there is a benefit to using an index built using subsequences of T rather than substrings, as we discussed in the \"Variations on k-mer indexes\" video.  We'll consider subsequences involving every N characters.  For example, if we split `ATATAT` into two substring partitions, we would get partitions `ATA` (the first half) and `TAT` (second half).  But if we split `ATATAT` into two  subsequences by taking every other character, we would get `AAA` (first, third and fifth characters) and `TTT` (second, fourth and sixth).\n",
    "\n",
    "Another way to visualize this is using numbers to show how each character of *P* is allocated to a partition.  Splitting a length-6 pattern into two substrings could be represented as `111222`, and splitting into two subsequences of every other character could be represented as `121212`.\n",
    "\n",
    "The following class `SubseqIndex` is a more general implementation of `Index` that additionally handles subsequences. It only considers subsequences that take every Nth character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4ca239c5-db89-47f9-8329-ca15e53e9797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec92f2d-9327-4aff-850d-b097e0810c7d",
   "metadata": {},
   "source": [
    "For example, if we do the below, we see `[('AAA', 0), ('TTT', 1)]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0887c90a-d95d-4e75-8f06-73c08c9f5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n"
     ]
    }
   ],
   "source": [
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915d210-1d78-4881-b9b8-dd14c9645b44",
   "metadata": {},
   "source": [
    "And if we query this index with `TTATAT`, we don't get a hit, because the subsequence `TAA` is not in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a1664301-0a5b-4846-86e4-6e334fcc438c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "p = 'TTATAT'\n",
    "print(ind.query(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2a339d-5987-4605-a027-948b9dd61488",
   "metadata": {},
   "source": [
    "But if we query with the second subsequence, we do get a hit, because `TTT` is in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9903868d-9997-417d-8191-97be75c81fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TATAT\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(p[1:])\n",
    "print(ind.query(p[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c4e02-2044-43bf-86fb-9f55a25f4a52",
   "metadata": {},
   "source": [
    "Write a function that, given a length-24 pattern P and given a SubseqIndex object built with k = 8 and ival = 3, finds all approximate occurrences of P within T with up to 2 mismatches.\n",
    "\n",
    "When using this function, how many total index hits are there when searching for GGCGCGGTGGCTCACGCCTGTAAT with up to 2 substitutions in the excerpt of human chromosome 1?  (Again, don't consider reverse complements.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9039e1aa-b803-419b-81c3-648cb5262b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subseq_approximate_match(p, t, n):\n",
    "    \n",
    "    segment_length = round(len(p)/(n+1))\n",
    "    all_matches = set()\n",
    "    ind = SubseqIndex(t, 8, 3)\n",
    "    ind_hits = 0\n",
    "\n",
    "    for i in range(n+1):\n",
    "        start = i # we don't have end anymore since we're taking every nth char\n",
    "        matches = ind.query(p[start:])\n",
    "        for m in matches:\n",
    "            ind_hits += 1\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "                \n",
    "            mismatches = 0\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            \n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m-start)\n",
    "                \n",
    "    return list(all_matches), ind_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f4af229-0325-4fa4-8fde-6d7b116d2441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "a, b = subseq_approximate_match('GGCGCGGTGGCTCACGCCTGTAAT', chromosome, 2)\n",
    "print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
